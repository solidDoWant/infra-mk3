---
clusterName: infra-mk3
endpoint: https://10.3.254.1:6443
nodes:
  - &talos-k8s-mixed
    hostname: talos-k8s-mixed-01
    ipAddress: 10.3.1.1
    installDiskSelector:
      # `/*` suffix is needed until
      # https://github.com/siderolabs/go-blockdevice/issues/114 is fixed
      busPath: /pci0000:00/0000:00:1d.0/0000:59:00.0/nvme/* # M.2 slot 2
    controlPlane: true
    machineSpec:
      secureboot: true
    # Previously, this used separate VLANs for Talos traffic and for
    # Kubernetes traffic. This worked well for traffic within the same subnet,
    # but caused problems with traffic from other subnets. Requests would come
    # in via the Kubernetes VLAN, and responses would be sent out via the
    # management VLAN. Normally this _could_ work, with the right firewall
    # rules, however the major issue was ICMP responses for fragmented packets.
    # With path MTU discovery enabled, ICMP responses would get sent back via
    # the wrong VLAN, and never make their way back to the correct interface.
    # This was likely in part due to how Cilium handles network traffic via
    # eBPF programs attached to specific interfaces.
    nameservers:
      - 10.3.0.254
    networkInterfaces:
      - &1g_1
        interface: enp87s0
        dummy: true
      - &1g_2
        interface: enp89s0
        dummy: true
      - &10g_1
        interface: &10g_1_name enp2s0f0
        mtu: &jumbo_mtu 9000
      - &10g_2
        interface: &10g_2_name enp2s0f1
        mtu: *jumbo_mtu
      - &bond_0
        interface: bond0
        bond:
          interfaces:
            - *10g_1_name
            - *10g_2_name
          mode: 802.3ad
          lacpRate: fast
          xmitHashPolicy: layer3+4
          miimon: 100
        mtu: *jumbo_mtu
        addresses:
          - 10.3.1.1/16
          - 10.3.2.1/32
        vip:
          ip: 10.3.254.1
        routes:
          - network: 0.0.0.0/0
            gateway: 10.3.0.254
    nodeLabels: &node_labels
      cilium.home.arpa/node.bgp-enabled: "true"
      root-ceph.flux.home.arpa/node.cluster-enabled: "true"
      katacontainers.io/kata-runtime: "true"
      # Topology labels should contain the label name in the value to ensure
      # that the value itself is unique
      topology.rook.io/chassis: chassis-talos-k8s-mixed-01 # TODO set this to template on next release
    nodeAnnotations:
      talos.home.arpa/installer-image: &installer_image >-
        factory.talos.dev/installer-secureboot/54416e4c74096eb53d4f8982e20ba9e45f2eb0d73dc55c27bf8f2f8ef9a588b2
    schematic:
      customization: &schematic_customization
        systemExtensions:
          officialExtensions:
            # Needed or the node will not boot
            - siderolabs/i915-ucode
            - siderolabs/intel-ucode
            - siderolabs/mei
            - siderolabs/thunderbolt
            # For virtualization/isolation
            - siderolabs/kata-containers
        # TODO set the following args on the installer only (not ISO):
        # src: https://cdrdv2-public.intel.com/332464/332464_710_Series_Datasheet_v_4_1.pdf
        # - intel_iommu=on
        # - iommu=pt
        extraKernelArgs:
          - &bond bond=bond0:enp2s0f0,enp2s0f1:mode=802.3ad,xmit_hash_policy=layer3+4:9000
          - ip=10.3.1.1::10.3.0.254:255.255.0.0:talos-k8s-mixed-01:bond0:off:10.3.0.254::10.3.0.254
    # This includes all of the above, except no kernel args
    # Support for a fix will be in the next release of talhelper
    # TODO need merge of https://github.com/budimanjojo/talhelper/pull/701 before switching
    talosImageURL: *installer_image
  - <<: *talos-k8s-mixed
    hostname: talos-k8s-mixed-02
    ipAddress: 10.3.1.2
    networkInterfaces:
      - *1g_1
      - *1g_2
      - *10g_1
      - *10g_2
      - <<: *bond_0
        addresses:
          - 10.3.1.2/16
          - 10.3.2.2/32
    nodeLabels:
      <<: *node_labels
      topology.rook.io/chassis: chassis-talos-k8s-mixed-02 # TODO set this to template on next release
    schematic:
      customization:
        <<: *schematic_customization
        extraKernelArgs:
          - *bond
          - ip=10.3.1.2::10.3.0.254:255.255.0.0:talos-k8s-mixed-02:bond0:off:10.3.0.254::10.3.0.254
  - <<: *talos-k8s-mixed
    hostname: talos-k8s-mixed-03
    ipAddress: 10.3.1.3
    networkInterfaces:
      - *1g_1
      - *1g_2
      - *10g_1
      - *10g_2
      - <<: *bond_0
        addresses:
          - 10.3.1.3/16
          - 10.3.2.3/32
    nodeLabels:
      <<: *node_labels
      topology.rook.io/chassis: chassis-talos-k8s-mixed-03 # TODO set this to template on next release
    schematic:
      customization:
        <<: *schematic_customization
        extraKernelArgs:
          - *bond
          - ip=10.3.1.3::10.3.0.254:255.255.0.0:talos-k8s-mixed-03:bond0:off:10.3.0.254::10.3.0.254
talosVersion: v1.8.2
kubernetesVersion: v1.31.2
allowSchedulingOnMasters: true
allowSchedulingOnControlPlanes: true
additionalApiServerCertSans: &sans
  - 127.0.0.1 # KubePrism
  # TODO add kube-vip address
additionalMachineCertSans: *sans
# Don't deploy a CNI by default
cniConfig:
  name: none
clusterPodNets:
  - 10.32.0.0/16
clusterSvcNets:
  - 10.33.0.0/16
patches:
  # Don't include the kernel args for non-ISO boot. Otherwise the image is
  # invalidated and secure boot won't load it.
  - |-
    - op: remove
      path: /machine/install/extraKernelArgs
  # Use NTP server running on the gateway
  - |-
    machine:
      time:
        servers:
          - 10.3.0.254
  # Disable IPv6
  - |-
    machine:
      sysctls:
        net.ipv6.conf.all.disable_ipv6: "1"
        net.ipv6.conf.default.disable_ipv6: "1"
  # Root FS disk encryption
  # TODO: implement disk encryption. Use a HA KMS server implementation
  # for the first key, hosted in the cluster. If that isn't available
  # (such as the case when all nodes are offline), require a HSM to decrypt
  # the first disk.
  # - |-
  #   machine:
  #     systemDiskEncryption:
  #       state:
  #         provider: luks2
  #         keys:
  #           - slot: 0
  #             tpm:
  #               checkSecurebootStatusOnEnroll: true
  #           - slot: 1
  #             static:
  #               passphrase: ${luks_password}
  # Enable Talos API access from k8s pods
  # Needed for OS upgrades
  - |-
    machine:
      features:
        kubernetesTalosAPIAccess:
          enabled: true # Enable Talos API access from Kubernetes pods.
          allowedRoles:
            - os:reader
            - os:admin
          allowedKubernetesNamespaces:
            - system-controllers
  # Enable KubePrism
  - |-
    machine:
      features:
        kubePrism:
          enabled: true
          port: 7443  # 6443 (API server default) + 1000
  # Configure DNS resolution
  - |-
    machine:
      features:
        hostDNS:
          enabled: true
          # This is broken with Cilium, see 
          # * https://github.com/cilium/cilium/issues/35153
          # * https://github.com/siderolabs/talos/pull/9200
          forwardKubeDNSToHost: false
          resolveMemberNames: true
  # Configure kubelet
  - |-
    machine:
      kubelet:
        extraConfig:
          # Equivalent of `rotate-server-certificates` arg, but config instead
          serverTLSBootstrap: true
          imageMaximumGCAge: 168h # One week
          imageGCHighThresholdPercent: 50
          imageGCLowThresholdPercent: 20
          maxPods: 128  # Probably higher than will realistically be scheduled
          serializeImagePulls: false
        nodeIP:
          validSubnets:
            - 10.3.1.0/16
  # Configure containerd for spegel
  - |-
    machine:
      files:
        - op: create
          path: /etc/cri/conf.d/20-customization.part
          permissions: 0o644
          content: |
            [plugins]
              [plugins.'io.containerd.cri.v1.images']
                discard_unpacked_layers = false
  # Configure containerd metrics
  # Disabled for now, this destroyed my cluster somehow last time it was enabled
  # - |-
  #   machine:
  #     files:
  #       - op: create
  #         path: /etc/cri/conf.d/30-metrics.part
  #         permissions: 0o644
  #         content: |
  #           [metrics]
  #             address = '0.0.0.0:11234'
  # Configure etcd
  # TODO limit this to processes on the each. Will probably require a custom extension, see
  # https://github.com/siderolabs/talos/blob/3e16ab135e2be8c9b652d67f9e7eadbc3691c5ca/internal/app/machined/pkg/controllers/network/nftables_chain_config.go#L162
  # Or maybe just a new address resource + nftableschain resource
  - |-
    cluster:
      etcd:
        advertisedSubnets:
          - 10.3.1.0/16
        extraArgs:
          listen-metrics-urls: http://0.0.0.0:2381
  # Configuration for Cilium
  - |-
    cluster:
      # Use Cilium's kube-proxy replacement
      proxy:
        disabled: true
  # Disable Talos-installed coredns, and instead install it manually
  - |-
    cluster:
      coreDNS:
        disabled: true
  # Enable only local etcd-based discover
  - |-
    cluster:
      discovery:
        enabled: true
        registries:
          kubernetes:
            disabled: false
          service:
            disabled: true
  # Enable workload scheduling on the control plane nodes
  - |-
    cluster:
      allowSchedulingOnControlPlanes: true
  # Load balance requests to metrics-server and other API server
  # services/extensions by sending traffic to each endpoint instead of the
  # service cluster IP
  - |-
    cluster:
      apiServer:
        extraArgs:
          enable-aggregator-routing: "true"
