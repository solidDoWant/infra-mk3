---
# yaml-language-server: $schema=https://raw.githubusercontent.com/bjw-s/helm-charts/main/charts/other/app-template/schemas/helmrelease-helm-v2.schema.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: vpn-gateway
spec:
  interval: 5m
  chart:
    spec:
      chart: app-template
      reconcileStrategy: ChartVersion
      sourceRef:
        kind: HelmRepository
        namespace: flux-system
        name: bjw-s-charts
      version: 3.7.3
  values:
    controllers:
      vpn-gateway:
        replicas: 2
        # This is just a statefulset so that pods are assigned a known index. This allows for a very slightly different
        # configuration for each pod, which is needed to ensure that each pod connects to a different VPN endpoint.
        # If this was implemented via two different deployments, then upgrades would terminate both pods at the same time,
        # which would cause a short downtime. With a statefulset, the pods are terminated one by one, so there is no downtime.
        type: statefulset
        initContainers:
          # Configures iptables rules to forward traffic from the VPN exit node to the destination IP.
          # The destination IP address is a load balancer service. Applications that want to receive
          # traffic via the VPN exit node should deploy a service with this IP address, and the port
          # that is forwarded by the VPN exit node. One application per port only!
          setup-nat:
            # Use the same image just to avoid pulling another image.
            image: &image # cspell:words qmcgaw
              repository: qmcgaw/gluetun
              tag: v3.40.0
            env:
              VPN_INTERFACE: tun0 # Interface for VPN traffic
              LOCAL_INTERFACE: eth0 # Interface for local traffic
              # All traffic for the ports that are forwarded by the VPN exit node will be forwarded again to this address.
              # Traffic will be masqueraded to this address so return traffic can be routed back to the VPN exit node.
              # It is important to use masquerading here instead of SNAT because the pod IP can change under certain conditions.
              PORT_FORWARDING_PORTS: >
                ${SECRET_VPN_FORWARDED_PORT_1}
                ${SECRET_VPN_FORWARDED_PORT_2}
                ${SECRET_VPN_FORWARDED_PORT_3}
                ${SECRET_VPN_FORWARDED_PORT_4}
                ${SECRET_VPN_FORWARDED_PORT_5}
              PORT_FORWARD_DESTINATION_IP: "${VPN_PORT_FORWARD_DESTINATION_LOAD_BALANCER_IP}"
              PROTOCOLS: "tcp udp" # Protocols to apply the rules to
            command:
              - /usr/local/bin/setup-nat.sh
            securityContext:
              readOnlyRootFilesystem: true
              capabilities:
                add:
                  - NET_ADMIN
        containers:
          gluetun:
            image: *image
            env:
              VPN_TYPE: wireguard
              BLOCK_MALICIOUS: "off"
              DNS_UPDATE_PERIOD: "0"
              HTTPPROXY: "on"
              HTTPPROXY_STEALTH: "on"
              SHADOWSOCKS: "on"
              PUID: "1000"
              PGID: "1000"
              VERSION_INFORMATION: "off"
              HEALTH_VPN_DURATION_INITIAL: 10s
              # Handled via netpols
              FIREWALL_ENABLED_DISABLING_IT_SHOOTS_YOU_IN_YOUR_FOOT: "off"
              # Allow all except for 10.32.0.0/11. This covers all in-cluster IP addresses.
              WIREGUARD_ALLOWED_IPS: "\
                0.0.0.0/5,\
                8.0.0.0/7,\
                10.0.0.0/11,\
                10.64.0.0/10,\
                10.128.0.0/9,\
                11.0.0.0/8,\
                12.0.0.0/6,\
                16.0.0.0/4,\
                32.0.0.0/3,\
                64.0.0.0/2,\
                128.0.0.0/1\
                "
              # These variable values are different for each pod. See the startup script below,
              # the statefulset note above, and the vpn-credentials secret.
              POD_SPECIFIC_VARS: "WIREGUARD_ADDRESSES SERVER_COUNTRIES"
              POD_NAME:
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.name
            command:
              - /usr/local/bin/startup.sh
            lifecycle:
              # From https://github.com/qdm12/gluetun-wiki/blob/main/setup/advanced/kubernetes.md#adding-ipv6-rule--file-exists
              # This must run on every container start, not the pod start, as it handles a gluetun bug when the container
              # is restarted.
              postStart:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ip rule del table 51820 || true
            securityContext:
              capabilities:
                add:
                  - DAC_OVERRIDE
                  - MKNOD
                  - NET_ADMIN
                  - CHOWN
            ports:
              - name: web-control
                containerPort: 8000
              - name: http-proxy
                containerPort: 8888
              - name: shadowsocks-tcp
                containerPort: 8388
              - name: shadowsocks-udp
                containerPort: 8388
                protocol: UDP
            probes:
              # From https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md#docker-healthcheck
              readiness: &gluetun_probe
                enabled: true
                custom: true
                spec: &gluetun_probe_spec
                  initialDelaySeconds: 15
                  exec:
                    command:
                      - /gluetun-entrypoint
                      - healthcheck
              liveness:
                <<: *gluetun_probe
                spec:
                  <<: *gluetun_probe_spec
                  initialDelaySeconds: 0
        pod:
          labels:
            endpoints.netpols.home.arpa/vpn-gateway: "true"
          dnsConfig:
            options:
              - name: ndots
                value: "1"
    configMaps:
      scripts:
        data:
          setup-nat.sh: |
            #!/bin/sh
            set -eux

            # Rewrite packets that are port-forwarded by the VPN to the destination IP:Port combo
            for PORT in ${PORT_FORWARDING_PORTS}; do
              for PROTOCOL in ${PROTOCOLS}; do
                iptables -t nat -A PREROUTING -i "${VPN_INTERFACE}" -p "${PROTOCOL}" --match addrtype ! --dst-type LOCAL --dport "${PORT}" -j DNAT --to-destination "${PORT_FORWARD_DESTINATION_IP}":"${PORT}"
              done
            done

            # Rewrite the source IP of outgoing packets to the local interface's IP
            for PORT in ${PORT_FORWARDING_PORTS}; do
              for PROTOCOL in ${PROTOCOLS}; do
                iptables -t nat -A POSTROUTING -o "${LOCAL_INTERFACE}"  -p "${PROTOCOL}" --dst "${PORT_FORWARD_DESTINATION_IP}" --dport "${PORT}" -j MASQUERADE
              done
            done

            # Rewrite packets that come in the local interface to the VPN interface with the VPN interface source address, but only if they are not destined for the local machine
            # TODO this is not needed as Cilium does not support routing to service addresses. When/if https://github.com/cilium/cilium/issues/40146 is implemented,
            # this can be enabled, and applications pods can route traffic via the VPN gateway by running `ip route add <VPN_SERVICE_IP> dev eth0 scope link && ip route add default via <VPN_SERVICE_IP> dev eth0`
            # iptables -t nat -A POSTROUTING -o "${VPN_INTERFACE}" --match addrtype ! --dst-type LOCAL,BROADCAST,ANYCAST,MULTICAST -j MASQUERADE
          startup.sh: |
            #!/bin/sh

            set -eu

            # Set vars based on the pod index. This is used to ensure that each pod connects to a different VPN endpoint.
            # If they connected to the same endpoint then the endpoint would (statelessly) send packets to each of the pods randomly.

            echo "Setting pod-specific variables for ${POD_NAME}:"
            for POD_SPECIFIC_VAR in ${POD_SPECIFIC_VARS}; do
              # Example: WIREGUARD_ADDRESSES="${WIREGUARD_ADDRESSES_0}"
              eval "export \"${POD_SPECIFIC_VAR}=\$${POD_SPECIFIC_VAR}_${POD_NAME##*-}\""
              echo "${POD_SPECIFIC_VAR}=$(eval echo "\$${POD_SPECIFIC_VAR}")"
            done

            echo
            echo "Starting gluetun..."
            exec /gluetun-entrypoint "$@"
    persistence:
      setup-nat-scripts: &scripts
        type: configMap
        identifier: scripts
        defaultMode: 0755
        advancedMounts:
          vpn-gateway:
            setup-nat:
              - path: /usr/local/bin/setup-nat.sh
                subPath: setup-nat.sh
      gluetun-scripts:
        <<: *scripts
        advancedMounts:
          vpn-gateway:
            gluetun:
              - path: /usr/local/bin/startup.sh
                subPath: startup.sh
    service:
      proxy:
        controller: vpn-gateway
        type: LoadBalancer
        annotations:
          lbipam.cilium.io/ips: 10.34.0.6
        ports:
          http-proxy:
            port: 8888
          shadowsocks-tcp:
            port: 8388
          shadowsocks-udp:
            port: 8388
            protocol: UDP
